{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-winter",
   "metadata": {},
   "source": [
    "## Parse Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/train/')\n",
    "subset = 'a'\n",
    "data_name = 'train_' + subset\n",
    "gt_file = data_dir / '{}_annotations.json'.format(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(gt_file), 'r') as f:\n",
    "    gts = json.load(f)\n",
    "\n",
    "imgs = gts['images']\n",
    "annotations = gts['annotations']\n",
    "categories = gts['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(categories)\n",
    "classes = []\n",
    "class_ids = []\n",
    "for category in categories:\n",
    "    classes.append(category['name'])\n",
    "    class_ids.append(category['id'])\n",
    "\n",
    "class_ids = np.array(class_ids)\n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-myrtle",
   "metadata": {},
   "source": [
    "### Display Number of Samples per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_per_class = np.zeros((num_classes), )\n",
    "for ann in annotations:\n",
    "    cid = ann['category_id']\n",
    "    num_samples_per_class[cid] += 1\n",
    "\n",
    "print('{} contains {} images, {} bboxes, {} categories'.format(data_name, len(imgs), len(annotations), len(np.nonzero(num_samples_per_class)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the figure size\n",
    "plt.rcParams['figure.figsize'] = [15, 22]\n",
    "fig, ax = plt.subplots()\n",
    "sorted_ids = np.argsort(num_samples_per_class)\n",
    "ax.barh(classes[sorted_ids], num_samples_per_class[sorted_ids])\n",
    "ax.set_ylabel('categories')\n",
    "ax.set_xlabel('number of samples (bboxes)')\n",
    "plt.title(data_name)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-specification",
   "metadata": {},
   "source": [
    "### Display Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_annotation(index):\n",
    "    img_info = imgs[index]\n",
    "    img_name = img_info['file_name']\n",
    "    img_path = data_dir / '{}_images'.format(subset) / img_name\n",
    "    img_id = img_info['id']\n",
    "    bbox_list = []\n",
    "    cls_list = []\n",
    "    for gt in annotations:\n",
    "        if gt['image_id'] == img_id:\n",
    "            bbox = gt['bbox']\n",
    "            cls_id = gt['category_id']\n",
    "            bbox_list.append(bbox)\n",
    "            cls_list.append(cls_id)\n",
    "    return {'img_path': img_path, 'bbox_list': bbox_list, 'cls_list': cls_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.randint(0, 255, size=(classes.shape[0], 3), dtype=np.uint8)\n",
    "def show_example(example_index):\n",
    "    gt_dict = get_image_annotation(example_index)\n",
    "    img_path = gt_dict['img_path']\n",
    "    bbox_list = gt_dict['bbox_list']\n",
    "    cls_list = gt_dict['cls_list']\n",
    "    img = cv2.imread(str(img_path))\n",
    "    for i, bbox in enumerate(bbox_list):\n",
    "        cls_id = cls_list[i]\n",
    "        cls_name = classes[cls_id]\n",
    "        x1, y1, w, h = bbox\n",
    "        color = colors[cls_id].tolist()\n",
    "        cv2.rectangle(img, (x1, y1), (x1+w, y1+h), color, 3)\n",
    "        cv2.putText(img, cls_name, (x1+10, y1 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    print(img.shape)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-green",
   "metadata": {},
   "source": [
    "### Statistics of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size: 720 x 960\n",
    "num_crowd = 0\n",
    "size_list = []\n",
    "for ann in annotations:\n",
    "    iscrowd = int(ann['iscrowd']) == 1\n",
    "    if iscrowd:\n",
    "        num_crowd += 1\n",
    "        continue\n",
    "    x, y, w, h = ann['bbox']\n",
    "    size_list.append([w, h])\n",
    "\n",
    "size_arr = np.array(size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 9\n",
    "ws = size_arr[:,0]\n",
    "hs = size_arr[:,1]\n",
    "# change the figure size\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].hist(ws, bins=n_bins)\n",
    "axs[1].hist(hs, bins=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "hist = ax.hist2d(ws, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://github.com/lars76/kmeans-anchor-boxes\n",
    "def iou(box, clusters):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) between a box and k clusters.\n",
    "    :param box: tuple or array, shifted to the origin (i. e. width and height)\n",
    "    :param clusters: numpy array of shape (k, 2) where k is the number of clusters\n",
    "    :return: numpy array of shape (k, 0) where k is the number of clusters\n",
    "    \"\"\"\n",
    "    x = np.minimum(clusters[:, 0], box[0])\n",
    "    y = np.minimum(clusters[:, 1], box[1])\n",
    "    if np.count_nonzero(x == 0) > 0 or np.count_nonzero(y == 0) > 0:\n",
    "        raise ValueError(\"Box has no area\")\n",
    "\n",
    "    intersection = x * y\n",
    "    box_area = box[0] * box[1]\n",
    "    cluster_area = clusters[:, 0] * clusters[:, 1]\n",
    "\n",
    "    iou_ = intersection / (box_area + cluster_area - intersection)\n",
    "\n",
    "    return iou_\n",
    "\n",
    "\n",
    "def avg_iou(boxes, clusters):\n",
    "    \"\"\"\n",
    "    Calculates the average Intersection over Union (IoU) between a numpy array of boxes and k clusters.\n",
    "    :param boxes: numpy array of shape (r, 2), where r is the number of rows\n",
    "    :param clusters: numpy array of shape (k, 2) where k is the number of clusters\n",
    "    :return: average IoU as a single float\n",
    "    \"\"\"\n",
    "    return np.mean([np.max(iou(boxes[i], clusters)) for i in range(boxes.shape[0])])\n",
    "\n",
    "\n",
    "def translate_boxes(boxes):\n",
    "    \"\"\"\n",
    "    Translates all the boxes to the origin.\n",
    "    :param boxes: numpy array of shape (r, 4)\n",
    "    :return: numpy array of shape (r, 2)\n",
    "    \"\"\"\n",
    "    new_boxes = boxes.copy()\n",
    "    for row in range(new_boxes.shape[0]):\n",
    "        new_boxes[row][2] = np.abs(new_boxes[row][2] - new_boxes[row][0])\n",
    "        new_boxes[row][3] = np.abs(new_boxes[row][3] - new_boxes[row][1])\n",
    "    return np.delete(new_boxes, [0, 1], axis=1)\n",
    "\n",
    "\n",
    "def kmeans(boxes, k, dist=np.median):\n",
    "    \"\"\"\n",
    "    Calculates k-means clustering with the Intersection over Union (IoU) metric.\n",
    "    :param boxes: numpy array of shape (r, 2), where r is the number of rows\n",
    "    :param k: number of clusters\n",
    "    :param dist: distance function\n",
    "    :return: numpy array of shape (k, 2)\n",
    "    \"\"\"\n",
    "    rows = boxes.shape[0]\n",
    "\n",
    "    distances = np.empty((rows, k))\n",
    "    last_clusters = np.zeros((rows,))\n",
    "\n",
    "    np.random.seed()\n",
    "\n",
    "    # the Forgy method will fail if the whole array contains the same rows\n",
    "    clusters = boxes[np.random.choice(rows, k, replace=False)]\n",
    "\n",
    "    while True:\n",
    "        for row in range(rows):\n",
    "            distances[row] = 1 - iou(boxes[row], clusters)\n",
    "\n",
    "        nearest_clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "        if (last_clusters == nearest_clusters).all():\n",
    "            break\n",
    "\n",
    "        for cluster in range(k):\n",
    "            clusters[cluster] = dist(boxes[nearest_clusters == cluster], axis=0)\n",
    "\n",
    "        last_clusters = nearest_clusters\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zhuanlan.zhihu.com/p/231168560\n",
    "# 聚类的数目\n",
    "CLUSTERS = 9\n",
    "# 模型中图像的输入尺寸，默认是一样的\n",
    "H, W = [720.0, 960.0]\n",
    "Ht, Wt = [416.0, 416.0]\n",
    "\n",
    "out = kmeans(size_arr, k=CLUSTERS)\n",
    "\n",
    "print('Original bbox clusters:')\n",
    "idx = np.argsort(out[:,0])[::-1]\n",
    "print(out[idx])\n",
    "print(\"Accuracy: {:.2f}%\".format(avg_iou(size_arr, out) * 100))\n",
    "\n",
    "out = out.astype(np.float32)\n",
    "out[:, 0] *= Wt / W\n",
    "out[:, 1] *= Ht / H\n",
    "\n",
    "out = out.astype(np.int32)\n",
    "idx = np.argsort(out[:,0])[::-1]\n",
    "out = out[idx]\n",
    "print('YOLO anchors:')\n",
    "print(out)\n",
    "\n",
    "ratios = np.around(out[:, 0] / out[:, 1], decimals=2).tolist()\n",
    "print(\"Ratios:\\n {}\".format(sorted(ratios)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
